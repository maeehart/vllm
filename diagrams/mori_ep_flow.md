# MORI-EP Expert Parallelism Flow Diagram

## Overview

MORI-EP (Multi-GPU Optimized Routing Interface for Expert Parallelism) handles
the All-to-All communication needed when experts are distributed across GPUs.

---

## ğŸ”‘ CORRECTED EXPERT ID FLOW (Jan 2026)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXPERT ID FLOW (CORRECTED)                              â”‚
â”‚                                                                             â”‚
â”‚  DeepSeek-R1: 256 experts (global IDs 0-255) across 8 GPUs                 â”‚
â”‚               32 experts per GPU (local IDs 0-31)                          â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 1: Router produces GLOBAL expert IDs                           â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   topk_ids = [70, 134, 5, 200, ...]  â† GLOBAL IDs (0-255)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 2: MORI dispatch sends tokens to correct ranks                 â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   Token with expert 70 â†’ sent to Rank 2 (owns experts 64-95)        â”‚   â”‚
â”‚  â”‚   MORI copies tokenIndices unchanged to output                      â”‚   â”‚
â”‚  â”‚   recv_topk_ids = [70, ...]  â† Still GLOBAL IDs!                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 3: Pass GLOBAL IDs to AITER unchanged                          â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   expert_topk_ids = recv_topk_ids  â† Keep GLOBAL! (70)              â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   âŒ PREVIOUS BUG: recv_topk_ids + offset â†’ 70+64 = 134 (WRONG!)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 4: AITER uses expert_map for globalâ†’local conversion           â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   On Rank 2:                                                        â”‚   â”‚
â”‚  â”‚     expert_map[70] = 6    â† Local ID for computation                â”‚   â”‚
â”‚  â”‚     expert_map[0]  = -1   â† Not on this rank, skip                  â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚   AITER kernel accesses: w1[6], w2[6] for local expert 6            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  âœ… expert_map handles conversion - NO manual offset adjustment needed!     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MORI-EP EXPERT PARALLELISM FLOW                          â”‚
â”‚                                                                                 â”‚
â”‚  DeepSeek-R1: 256 experts Ã· 8 GPUs = 32 experts/GPU, topk=8                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input: hidden_states [M, H]  (M tokens, H=7168 hidden dim)
       topk_ids [M, K]       (K=8 selected experts per token)
       topk_weights [M, K]   (routing weights)

                    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                    â•‘   GPU 0        GPU 1    ...  GPU 7â•‘
                    â•‘  exp 0-31    exp 32-63     exp 224-255
                    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Full Forward Pass Through FusedMoE Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FusedMoE.forward() [layer.py:845-920]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Router.forward() [router/__init__.py]                    â”‚
â”‚                                                                              â”‚
â”‚  Input:  hidden_states [M, H]                                                â”‚
â”‚  Output: topk_ids [M, K], topk_weights [M, K]                               â”‚
â”‚                                                                              â”‚
â”‚  For DeepSeek-R1:                                                            â”‚
â”‚  - Uses grouped_topk with e_score_correction_bias                            â”‚
â”‚  - On ROCm: calls rocm_aiter_grouped_topk()                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               FusedMoEModularKernel.forward() [modular_kernel.py:1171]       â”‚
â”‚                                                                              â”‚
â”‚  1. _prepare()  â†’ Dispatch tokens to expert owners                           â”‚
â”‚  2. _fused_experts() â†’ Compute expert outputs                                â”‚
â”‚  3. _finalize() â†’ Combine results back                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step 1: PREPARE (Dispatch Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      _prepare() [modular_kernel.py:938-1010]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MoriPrepareAndFinalize.prepare_async() [mori_prepare_finalize.py] â”‚
â”‚                                                                              â”‚
â”‚  def prepare_async(                                                          â”‚
â”‚      self,                                                                   â”‚
â”‚      a1: torch.Tensor,           # [M, H] input activations                  â”‚
â”‚      topk_weights: torch.Tensor, # [M, K] router weights                     â”‚
â”‚      topk_ids: torch.Tensor,     # [M, K] selected expert IDs (global)       â”‚
â”‚      num_experts: int,           # 256 total experts                         â”‚
â”‚      expert_map: torch.Tensor,   # NOT used with MORI                        â”‚
â”‚      apply_router_weight_on_input: bool,                                     â”‚
â”‚      quant_config: FusedMoEQuantConfig,                                      â”‚
â”‚  ) -> Callable[[], PrepareResultType]:                                       â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Step 1: Optional weight application (for topk=1)                       â”‚  â”‚
â”‚  â”‚   if apply_router_weight_on_input:                                     â”‚  â”‚
â”‚  â”‚       a1 = a1 * topk_weights.to(a1.dtype)                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Step 2: Quantization Strategy                                          â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   Strategy A (FP8 dispatch): use_fp8_dispatch=True                     â”‚  â”‚
â”‚  â”‚   - Quantize BEFORE dispatch for 2x bandwidth savings                  â”‚  â”‚
â”‚  â”‚   - a1q, a1q_scale = moe_kernel_quantize_input(a1, ...)               â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   Strategy B (BF16 dispatch): use_fp8_dispatch=False (DEFAULT)         â”‚  â”‚
â”‚  â”‚   - Dispatch BF16, quantize AFTER receive                              â”‚  â”‚
â”‚  â”‚   - a1q = a1, a1q_scale = None                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Step 3: Call _do_dispatch()                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              _do_dispatch() [mori_prepare_finalize.py:199-240]               â”‚
â”‚                                                                              â”‚
â”‚  # MORI dispatch - send tokens to expert owners                              â”‚
â”‚  dispatch_result = self.ep_op.dispatch(                                      â”‚
â”‚      input=tokens,      # [M, H] or [M_quant, H] if FP8                     â”‚
â”‚      weights=topk_weights,  # [M, K]                                        â”‚
â”‚      scales=token_scales,   # None or [M, scale_dim] for FP8                â”‚
â”‚      indices=topk_ids.to(torch.int32),  # [M, K] global expert IDs          â”‚
â”‚  )                                                                           â”‚
â”‚                                                                              â”‚
â”‚  Returns: (recv_x, recv_weights, recv_scale, recv_topk_ids, recv_src_pos)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MORI launch_dispatch() [mori/cpp/...]                                 â”‚
â”‚                                                                              â”‚
â”‚  ALL-TO-ALL COMMUNICATION:                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   GPU 0: tokens for experts 0-31     â”€â”€â”€â”€â”€â”€â”                          â”‚  â”‚
â”‚  â”‚   GPU 1: tokens for experts 32-63    â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º All-to-All via XGMI   â”‚  â”‚
â”‚  â”‚   ...                                      â”‚                          â”‚  â”‚
â”‚  â”‚   GPU 7: tokens for experts 224-255  â”€â”€â”€â”€â”€â”€â”˜                          â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   After dispatch, each GPU has ALL tokens routed to its local experts â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   GPU 0 receives: tokens from ALL GPUs that selected experts 0-31     â”‚  â”‚
â”‚  â”‚   GPU 1 receives: tokens from ALL GPUs that selected experts 32-63    â”‚  â”‚
â”‚  â”‚   ...                                                                  â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Output buffers are FIXED SIZE: [max_num_tokens, hidden_dim]                 â”‚
â”‚  (This is important - causes size mismatch issues during CUDA graph)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              _receiver() [mori_prepare_finalize.py:242-315]                  â”‚
â”‚                                                                              â”‚
â”‚  # Unpack dispatch result                                                    â”‚
â”‚  recv_x_full = dispatch_result[0]      # [MAX_RECV, H] FIXED SIZE buffer   â”‚
â”‚  recv_weights_full = dispatch_result[1]# [MAX_RECV, K] weights             â”‚
â”‚  recv_scale_full = dispatch_result[2]  # [MAX_RECV, scale_dim] or None     â”‚
â”‚  recv_topk_ids = dispatch_result[3]    # [MAX_RECV, K] GLOBAL expert IDs   â”‚
â”‚  total_recv_tokens = dispatch_result[4]# Scalar: actual valid token count  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âš ï¸ CRITICAL: Slice to valid tokens only!                               â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ MORI returns FIXED-SIZE buffers [max_num_tokens, ...]                  â”‚  â”‚
â”‚  â”‚ Only positions 0..total_recv_tokens-1 contain valid data!              â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ num_valid = total_recv_tokens.item()                                   â”‚  â”‚
â”‚  â”‚ recv_x = recv_x_full[:num_valid]                                       â”‚  â”‚
â”‚  â”‚ recv_weights = recv_weights_full[:num_valid]                           â”‚  â”‚
â”‚  â”‚ recv_topk_ids = recv_topk_ids[:num_valid]                              â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ NOTE: .item() breaks CUDA graph capture! Use --enforce-eager for now   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âœ… Expert IDs: Keep GLOBAL, pass to AITER unchanged                    â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ MORI dispatch returns the ORIGINAL global expert IDs (0-255)           â”‚  â”‚
â”‚  â”‚ from the router. It just copies tokenIndices to shmemOutIndices.       â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ expert_topk_ids = recv_topk_ids  # Keep as-is! (GLOBAL IDs)            â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ AITER expects GLOBAL IDs when expert_map is provided:                  â”‚  â”‚
â”‚  â”‚   expert_map[global_id] â†’ local_id (or -1 if not on this rank)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Strategy B post-dispatch quantization (if not FP8 dispatch)            â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ if not quant_config.is_block_quantized:                                â”‚  â”‚
â”‚  â”‚     expert_x, expert_x_scale = moe_kernel_quantize_input(expert_x, ...)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Return: (expert_x, expert_x_scale, None, expert_topk_ids, recv_weights)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step 2: FUSED EXPERTS (Computation Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  _fused_experts() [modular_kernel.py:1012-1100]              â”‚
â”‚                                                                              â”‚
â”‚  # Get problem dimensions                                                    â”‚
â”‚  M_full = a1q.size(0)  # Number of tokens received by this rank             â”‚
â”‚                                                                              â”‚
â”‚  # Allocate output buffer                                                    â”‚
â”‚  fused_out = torch.empty_like(a1q, dtype=in_dtype)  # [N_recv, H]           â”‚
â”‚                                                                              â”‚
â”‚  # Call AiterExperts.apply()                                                 â”‚
â”‚  self.fused_experts.apply(...)                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                AiterExperts.apply() [rocm_aiter_fused_moe.py:310-345]        â”‚
â”‚                                                                              â”‚
â”‚  def apply(                                                                  â”‚
â”‚      self,                                                                   â”‚
â”‚      output: torch.Tensor,          # [N_recv, H] output buffer             â”‚
â”‚      hidden_states: torch.Tensor,   # [N_recv, H] received tokens           â”‚
â”‚      w1: torch.Tensor,              # [32, I, H] gate/up weights            â”‚
â”‚      w2: torch.Tensor,              # [32, H, I] down weights               â”‚
â”‚      topk_weights: torch.Tensor,    # [N_recv, K]                           â”‚
â”‚      topk_ids: torch.Tensor,        # [N_recv, K] now LOCAL expert IDs      â”‚
â”‚      activation: str,               # "silu"                                 â”‚
â”‚      global_num_experts: int,       # 256                                   â”‚
â”‚      expert_map: torch.Tensor,      # Maps globalâ†’local expert IDs          â”‚
â”‚      ...                                                                     â”‚
â”‚  ):                                                                          â”‚
â”‚      result = rocm_aiter_fused_experts(...)                                  â”‚
â”‚      output.copy_(result)                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           rocm_aiter_fused_experts() [rocm_aiter_fused_moe.py:159-225]       â”‚
â”‚                                                                              â”‚
â”‚  # AITER kernel handles all 32 local experts                                 â”‚
â”‚  rocm_aiter_ops.fused_moe(                                                   â”‚
â”‚      hidden_states,    # [N_recv, H]                                        â”‚
â”‚      w1,               # [32, I, H] local expert gate/up weights            â”‚
â”‚      w2,               # [32, H, I] local expert down weights               â”‚
â”‚      topk_weights,     # [N_recv, K]                                        â”‚
â”‚      topk_ids,         # [N_recv, K]                                        â”‚
â”‚      expert_mask=expert_map,                                                 â”‚
â”‚      quant_method=...,                                                       â”‚
â”‚      activation_method=SILU,                                                 â”‚
â”‚      ...                                                                     â”‚
â”‚  )                                                                           â”‚
â”‚                                                                              â”‚
â”‚  Internally for each token:                                                  â”‚
â”‚  1. Route to selected experts (up to K=8 per token)                          â”‚
â”‚  2. For each selected expert e in token's topk_ids:                          â”‚
â”‚     - x1 = x @ w1[e]  # [H] â†’ [I]  gate/up projection                       â”‚
â”‚     - x1 = SiLU(x1[:I/2]) * x1[I/2:]  # SwiGLU activation                   â”‚
â”‚     - x2 = x1 @ w2[e]  # [I/2] â†’ [H]  down projection                       â”‚
â”‚  3. Weighted sum: out = sum(topk_weights[i] * expert_out[i])                â”‚
â”‚                                                                              â”‚
â”‚  Returns: [N_recv, H] expert outputs                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step 3: FINALIZE (Combine Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   _finalize() [modular_kernel.py:1102-1168]                  â”‚
â”‚                                                                              â”‚
â”‚  # Call finalize_async and wait for result                                   â”‚
â”‚  receiver = self.prepare_finalize.finalize_async(...)                        â”‚
â”‚  receiver()  # Execute combine and copy result                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          MoriPrepareAndFinalize._finalize_impl() [mori_prepare_finalize.py]  â”‚
â”‚                                                                              â”‚
â”‚  def _finalize_impl(                                                         â”‚
â”‚      self,                                                                   â”‚
â”‚      output: torch.Tensor,           # [M, H] final output buffer           â”‚
â”‚      fused_expert_output: torch.Tensor,  # [N_recv, H] expert results       â”‚
â”‚      topk_weights: torch.Tensor,     # [M, K] original weights              â”‚
â”‚      topk_ids: torch.Tensor,         # [M, K] original expert IDs           â”‚
â”‚      apply_router_weight_on_input: bool,                                     â”‚
â”‚      weight_and_reduce_impl: TopKWeightAndReduce,                            â”‚
â”‚      do_async: bool,                                                         â”‚
â”‚  ):                                                                          â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Apply weights if using delegate reducer                                â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ if isinstance(weight_and_reduce_impl, TopKWeightAndReduceDelegate):    â”‚  â”‚
â”‚  â”‚     weight_and_reduce_impl = TopKWeightAndReduceContiguous()           â”‚  â”‚
â”‚  â”‚ fused_expert_output = weight_and_reduce_impl.apply(...)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MORI combine - returns results to original token owners                â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ combine_result = self.ep_op.combine(                                   â”‚  â”‚
â”‚  â”‚     input=fused_expert_output,  # [N_recv, H] BF16                     â”‚  â”‚
â”‚  â”‚     weights=topk_weights if not apply_router_weight_on_input else None,â”‚  â”‚
â”‚  â”‚     indices=topk_ids.to(torch.int32),                                  â”‚  â”‚
â”‚  â”‚     call_reset=True,  # Reset for next iteration                       â”‚  â”‚
â”‚  â”‚ )                                                                      â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ combined_x = combine_result[0]  # [max_num_tokens, H] FIXED SIZE!      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âš ï¸  CRITICAL FIX: Slice to actual batch size                           â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ # MORI combine returns FIXED-SIZE buffer [max_num_tokens, hidden_dim]  â”‚  â”‚
â”‚  â”‚ # but actual batch may be smaller (especially during CUDA graph)       â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ num_tokens = output.shape[0]                                           â”‚  â”‚
â”‚  â”‚ if combined_x.shape[0] != num_tokens:                                  â”‚  â”‚
â”‚  â”‚     combined_x = combined_x[:num_tokens]  # SLICE TO ACTUAL SIZE       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Copy to output                                                         â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚ output.copy_(combined_x, non_blocking=True)                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MORI launch_combine() [mori/cpp/...]                                  â”‚
â”‚                                                                              â”‚
â”‚  ALL-TO-ALL COMMUNICATION (REVERSE):                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   GPU 0: expert outputs for experts 0-31   â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚  â”‚   GPU 1: expert outputs for experts 32-63  â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º All-to-All      â”‚  â”‚
â”‚  â”‚   ...                                            â”‚    via XGMI        â”‚  â”‚
â”‚  â”‚   GPU 7: expert outputs for experts 224-255 â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   After combine, each GPU has its ORIGINAL tokens back                 â”‚  â”‚
â”‚  â”‚   with expert computation results                                      â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚   GPU 0 receives: expert outputs for tokens it originally owned       â”‚  â”‚
â”‚  â”‚   GPU 1 receives: expert outputs for tokens it originally owned       â”‚  â”‚
â”‚  â”‚   ...                                                                  â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Memory Layout and Buffer Sizes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MORI BUFFER ALLOCATION                              â”‚
â”‚                                                                              â”‚
â”‚  Created in create_mori_ep_op() [mori_utils.py]                             â”‚
â”‚                                                                              â”‚
â”‚  MoriEpConfig:                                                               â”‚
â”‚  â”œâ”€â”€ max_num_tokens = 8192 (from scheduler_config.max_num_batched_tokens)   â”‚
â”‚  â”œâ”€â”€ hidden_dim = 7168                                                       â”‚
â”‚  â”œâ”€â”€ topk = 8                                                                â”‚
â”‚  â”œâ”€â”€ num_experts = 256                                                       â”‚
â”‚  â”œâ”€â”€ num_experts_per_rank = 32                                              â”‚
â”‚  â””â”€â”€ world_size = 8                                                          â”‚
â”‚                                                                              â”‚
â”‚  MORI Symmetric Heap:                                                        â”‚
â”‚  â”œâ”€â”€ MORI_SHMEM_HEAP_SIZE=12G (shared across all 8 GPUs!)                   â”‚
â”‚  â”œâ”€â”€ Per-rank allocation: ~1.5GB                                            â”‚
â”‚  â”‚                                                                           â”‚
â”‚  â”‚  Required per rank for dispatch:                                          â”‚
â”‚  â”‚  - Input buffer: max_tokens Ã— hidden_dim Ã— 2 bytes (BF16)                â”‚
â”‚  â”‚  - Weight buffer: max_tokens Ã— topk Ã— 4 bytes (FP32)                     â”‚
â”‚  â”‚  - Index buffer: max_tokens Ã— topk Ã— 4 bytes (INT32)                     â”‚
â”‚  â”‚  - Metadata: ~misc overhead                                               â”‚
â”‚  â”‚                                                                           â”‚
â”‚  â”‚  Estimated: 8192 Ã— 7168 Ã— 2 + 8192 Ã— 8 Ã— 4 Ã— 2 â‰ˆ 117MB + 0.5MB = ~120MB â”‚
â”‚  â”‚  But MORI allocates for worst-case all-to-all: ~940MB per rank           â”‚
â”‚  â”‚  Total: 940MB Ã— 8 = 7.5GB minimum â†’ set to 12GB for safety               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                              â”‚
â”‚  âš ï¸  MORI OUTPUT BUFFERS ARE FIXED SIZE!                                     â”‚
â”‚  â”œâ”€â”€ dispatch returns: [max_num_tokens, hidden_dim]                         â”‚
â”‚  â”œâ”€â”€ combine returns: [max_num_tokens, hidden_dim]                          â”‚
â”‚  â””â”€â”€ Actual batch size may be smaller â†’ MUST SLICE!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Potential Performance Issues

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ” POTENTIAL SLOWNESS CAUSES                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. DOUBLE WEIGHT APPLICATION?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Check if weights are being applied TWICE:
   
   a) In _finalize_impl():
      fused_expert_output = weight_and_reduce_impl.apply(...)  # Applies weights?
      
   b) In MORI combine():
      combine_result = self.ep_op.combine(
          input=fused_expert_output,
          weights=topk_weights,  # <-- Passes weights again!
          ...
      )
   
   âš ï¸  If both apply weights, we have double computation!

2. TOPKWEIGHTANDREDUCE MISMATCH
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   In finalize, we check for TopKWeightAndReduceDelegate and swap to Contiguous:
   
   if isinstance(weight_and_reduce_impl, TopKWeightAndReduceDelegate):
       weight_and_reduce_impl = TopKWeightAndReduceContiguous()
   
   But AiterExperts returns TopKWeightAndReduceNoOP:
   
   class AiterExperts:
       def finalize_weight_and_reduce_impl(self) -> mk.TopKWeightAndReduce:
           return TopKWeightAndReduceNoOP()  # <-- NoOp!
   
   So weight_and_reduce_impl.apply() does NOTHING!
   
   Then MORI combine() receives weights and applies them.
   This seems correct - but verify MORI actually uses the weights.

3. EXTRA COPY OPERATIONS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   In AiterExperts.apply():
      result = rocm_aiter_fused_experts(...)
      output.copy_(result)  # Copy #1
   
   In _finalize_impl():
      output.copy_(combined_x, non_blocking=True)  # Copy #2
   
   âš ï¸  Two copies per MoE layer Ã— 61 MoE layers = 122 extra copies!

4. SYNCHRONIZATION POINTS?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Check if there are hidden synchronization points:
   
   - MORI dispatch() - likely async
   - MORI combine(call_reset=True) - does reset cause sync?
   - output.copy_(combined_x, non_blocking=True) - async copy
   
   âš ï¸  call_reset=True might force synchronization!

5. âœ… EXPERT ID HANDLING (FIXED Jan 2026)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Previous BUG: We were ADDING rank_expert_offset to global IDs!
   
      expert_topk_ids = recv_topk_ids + rank_expert_offset  # âŒ WRONG!
      # Global ID 70 on rank 2 â†’ 70 + 64 = 134 (out of range!)
   
   FIX: MORI returns GLOBAL IDs (same as router output). Pass unchanged:
   
      expert_topk_ids = recv_topk_ids  # âœ… Keep global IDs (0-255)
      # AITER uses expert_map[70] â†’ 6 (local) internally
   
6. QUANTIZATION STRATEGY
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Default use_fp8_dispatch=False â†’ Strategy B (BF16 dispatch)
   
   This means:
   - Dispatch sends BF16 (2 bytes per element)
   - After receive, we quantize to FP8 (if needed for expert compute)
   
   âš ï¸  FP8 dispatch would send half the data!
   
7. MORI BUFFER REGISTRATION
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   MORI config has: use_external_inp_buf=True
   
   This might mean input buffers are NOT pre-registered with MORI,
   causing extra memory registration overhead per dispatch.

8. AITER EXPERT COMPUTATION
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   AiterExperts doesn't use expert_map efficiently with MORI?
   
   MORI returns LOCAL expert IDs (0-31 for each rank)
   But we remap to GLOBAL and pass expert_map to AITER.
   
   Does AITER then re-map global â†’ local internally?
   That's redundant!
```

---

## Recommendations for Investigation

```
1. Add timing instrumentation:
   - Time MORI dispatch()
   - Time AITER fused_moe()
   - Time MORI combine()
   - Time expert ID remapping
   - Time weight application

2. Check weight application:
   - Does MORI combine() actually use the weights parameter?
   - Is weight_and_reduce_impl doing anything?

3. Try FP8 dispatch:
   export VLLM_MORI_EP_USE_FP8_DISPATCH=1
   - Should halve dispatch/combine bandwidth

4. Check for unnecessary expert_map usage:
   - If MORI gives local IDs, don't remap to global then back to local

5. Profile MORI reset():
   - Does call_reset=True cause synchronization?

6. Check buffer registration:
   - Is MORI re-registering buffers each time?
```

---

## ğŸ” INVESTIGATION RESULTS (Jan 2026)

After analyzing the code, here are the key findings:

### 1. âœ… NO DOUBLE WEIGHT APPLICATION
```
AITER fused_moe:
â”œâ”€â”€ Takes topk_weights as input
â”œâ”€â”€ Applies weights during expert computation: out_i = sum(w_j * expert_j(x))
â”œâ”€â”€ Returns [M_recv, H] with weights already applied
â””â”€â”€ That's why it returns TopKWeightAndReduceNoOP

MORI combine:
â”œâ”€â”€ Takes weights as input BUT...
â”œâ”€â”€ Only ACCUMULATES weights separately: shmemCombineOutWeightsMemObj
â”œâ”€â”€ Does NOT multiply tokens by weights
â”œâ”€â”€ Just does All-to-All reduce (sum) of token data
â””â”€â”€ We DON'T USE the accumulated weights (combine_result[0] only)

CONCLUSION: Weight application is correct, but we're doing unnecessary work
           by passing weights to MORI (they just get accumulated and discarded)
```

### 2. âš ï¸ UNNECESSARY OPERATIONS

```python
# In _finalize_impl:
combine_result = self.ep_op.combine(
    input=fused_expert_output,
    weights=topk_weights if not apply_router_weight_on_input else None,  # âŒ UNNECESSARY
    indices=topk_ids.to(torch.int32),
    call_reset=True,
)
combined_x = combine_result[0]  # We only use tokens, discard weights!
```

**Fix**: Pass `weights=None` since AITER already applied weights:
```python
combine_result = self.ep_op.combine(
    input=fused_expert_output,
    weights=None,  # âœ… AITER already applied weights
    indices=topk_ids.to(torch.int32),
    call_reset=True,
)
```

### 3. âœ… EXPERT ID BUG FIXED

```python
# BEFORE (WRONG):
expert_topk_ids = recv_topk_ids + self.rank_expert_offset  # âŒ 70 â†’ 134

# AFTER (CORRECT):
expert_topk_ids = recv_topk_ids  # âœ… Keep global IDs unchanged
```

MORI's C++ dispatch copies original tokenIndices to output unchanged:
```cpp
// intranode.hpp line 135-137:
args.shmemOutIndicesMemObj[...] = args.tokenIndices[...]  // Original global IDs!
```

AITER expects global IDs when expert_map is provided:
- expert_map[global_id] â†’ local_id (or -1 if not on this rank)
- NO modification needed in our code!

### 4. âš ï¸ CUDA GRAPH COMPATIBILITY & BUFFER SLICING

MORI returns FIXED-SIZE buffers:
- dispatch returns: [8192, 7168] but only [0:N_valid] has real data!
- combine returns: [8192, 7168] (fixed)

**Critical Bug Found**: Without slicing, expert kernels compute on garbage data!

```python
# BEFORE (WRONG): Pass full 8192 tokens (most are garbage)
expert_x = recv_x_full  # [8192, H] - positions N+1..8191 are uninitialized!

# AFTER (CORRECT): Slice to valid tokens only
num_valid = total_recv_tokens.item()  # e.g., 512
expert_x = recv_x_full[:num_valid]    # [512, H] - only real data
```

**Trade-off**: Using `.item()` breaks CUDA graph capture. Must use `--enforce-eager`.
For CUDA graph support, need kernel-level masking or pre-registered buffers.

### 5. ğŸ”´ POTENTIAL ROOT CAUSE: Strategy B (BF16 dispatch)

Default: `use_fp8_dispatch = False`

This means:
1. Dispatch sends BF16 (2 bytes/element) over XGMI
2. After receive, quantize to FP8 for expert compute
3. Expert compute in FP8
4. Combine sends BF16 (2 bytes/element) over XGMI

With FP8 dispatch:
1. Quantize BEFORE dispatch (on each GPU locally)
2. Dispatch sends FP8 (1 byte/element) - 2x bandwidth savings
3. Expert compute in FP8
4. Combine sends BF16 (still 2 bytes)

For 70k tokens Ã— 8 experts Ã— 7168 hidden:
- BF16 dispatch: ~4GB per All-to-All
- FP8 dispatch: ~2GB per All-to-All

### 6. ğŸ”´ 61 MoE LAYERS Ã— 2 All-to-All = 122 Communications

For 70k input tokens:
- Each All-to-All moves ~4GB (BF16)
- 122 Ã— 4GB = ~488GB total data movement
- Even with XGMI at ~300GB/s, this is ~1.6 seconds just for communication!

---

## Implemented Fixes (Jan 2026)

### âœ… Fix 1: Expert ID Handling (CRITICAL - was causing garbage output!)
```python
# BEFORE (WRONG):
expert_topk_ids = recv_topk_ids + self.rank_expert_offset  # 70 â†’ 134 âŒ

# AFTER (CORRECT):
expert_topk_ids = recv_topk_ids  # 70 stays 70, expert_map handles conversion âœ…
```

### âœ… Fix 2: Slice Dispatch Buffer to Valid Tokens
```python
# BEFORE (WRONG): Used full 8192-token buffer (garbage data!)
expert_x = recv_x_full  # [8192, H] includes uninitialized garbage

# AFTER (CORRECT): Slice to actual received tokens
num_valid = total_recv_tokens.item()
expert_x = recv_x_full[:num_valid]  # [N_valid, H] only real data
```

### âœ… Fix 3: Don't Pass Weights to MORI Combine
```python
# BEFORE: Unnecessary weight transfer
combine_result = self.ep_op.combine(..., weights=topk_weights, ...)

# AFTER: AITER already applied weights
combine_result = self.ep_op.combine(..., weights=None, ...)
```

### âš ï¸ Known Limitation: CUDA Graphs
The `.item()` call in buffer slicing breaks CUDA graph capture.
Must use `--enforce-eager` until kernel-level masking is implemented.

---

## Remaining Optimizations (Future Work)

### Priority 1: Enable FP8 Dispatch
```bash
export VLLM_MORI_EP_USE_FP8_DISPATCH=1
```
Expected: ~2x bandwidth reduction for dispatch (1 byte vs 2 bytes)

### Priority 2: CUDA Graph Support
Need kernel-level support for `num_valid_tokens` parameter to avoid `.item()`.
Or use pre-registered fixed-size buffers with masking in AITER kernel.

---

## Quick Test Commands

```bash
# Test with FP8 dispatch
VLLM_MORI_EP_USE_FP8_DISPATCH=1 \
MORI_SHMEM_HEAP_SIZE=12G \
vllm serve deepseek-ai/DeepSeek-R1 \
  --host localhost --port 8000 \
  --tensor-parallel-size 8 \
  --max-model-len 72000 \
  --trust-remote-code \
  --enable-expert-parallel \
  --all2all-backend mori_ep \
  --kv-cache-dtype fp8
```

---

## Data Flow Summary

```
Input: [M tokens] Ã— [H=7168]

DISPATCH (All-to-All #1):
â”œâ”€â”€ GPU0 sends tokens for experts 0-31 to GPU0 (local)
â”œâ”€â”€ GPU0 sends tokens for experts 32-63 to GPU1
â”œâ”€â”€ ...
â””â”€â”€ Each GPU receives ALL tokens routed to its 32 experts

COMPUTE:
â”œâ”€â”€ Each GPU runs AITER on its 32 local experts
â”œâ”€â”€ Input: [N_recv tokens] Ã— [H]
â”œâ”€â”€ Output: [N_recv tokens] Ã— [H]
â””â”€â”€ Where N_recv varies per GPU based on routing

COMBINE (All-to-All #2):
â”œâ”€â”€ GPU0 receives expert outputs for its original tokens
â”œâ”€â”€ GPU1 receives expert outputs for its original tokens
â”œâ”€â”€ ...
â””â”€â”€ Final: [M tokens] Ã— [H] (original shape)
```

