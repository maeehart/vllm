# MORI-EP Data Flow (MoE Layer with TP + EP)

## Context
- **Model**: DeepSeek-R1 (256 experts, topk=8)
- **Setup**: 8 GPUs with TP=8 + EP=8, each owns 32 experts
- **Mode**: Decode (1 token per rank, but with TP=8, ALL ranks have SAME token!)
- **Rank 0** owns experts **0-31**

---

## âš ï¸ KEY INSIGHT: TP + EP Interaction

With **Tensor Parallelism (TP=8)**, all 8 GPUs process the **SAME token**!
- All 8 ranks dispatch the **identical** token with **identical** routing
- Each expert-owning rank receives the same token **8 times** from 8 different source ranks
- `src_token_pos = src_rank Ã— max_tokens + local_token_idx`
- Same `local_token_idx` across ranks = same logical token

---

## CURRENT IMPLEMENTATION FLOW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STEP 1: DISPATCH (on each rank)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  INPUT:                                                                         â”‚
â”‚    tokens shape = [M, 7168]             â† M tokens from this rank               â”‚
â”‚    topk_ids shape = [M, 8]              â† 8 selected experts per token          â”‚
â”‚    topk_weights shape = [M, 8]          â† router weights                        â”‚
â”‚                                                                                 â”‚
â”‚  MORI ep_op.dispatch() routes tokens to expert-owning ranks:                    â”‚
â”‚    - Token T with topk=[E0, E1, ..., E7] â†’ sent to ranks owning these experts   â”‚
â”‚    - Each rank receives entries for its local experts only                      â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                                   ALL-TO-ALL
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STEP 2: RECEIVE & SLICE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  MORI returns fixed-size buffers; slice to valid tokens:                        â”‚
â”‚                                                                                 â”‚
â”‚  total_recv_tokens = dispatch_result[4]   â† GPU tensor with actual count        â”‚
â”‚  num_valid = total_recv_tokens.item()     â† e.g., 8 for decode, 65536 prefill   â”‚
â”‚                                                                                 â”‚
â”‚  expert_x = recv_x[:num_valid]            â† [N_recv, H] token embeddings        â”‚
â”‚  recv_topk_ids = recv_topk_ids[:num_valid]â† [N_recv, 8] all 8 expert IDs        â”‚
â”‚  recv_weights = recv_weights[:num_valid]  â† [N_recv, 8] all 8 weights           â”‚
â”‚                                                                                 â”‚
â”‚  src_token_pos = ep_op.get_dispatch_src_token_pos()[:num_valid]                 â”‚
â”‚    â† Format: src_rank Ã— max_tokens_per_rank + local_token_idx                   â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 3: DEDUP BY LOCAL TOKEN INDEX âœ…                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  ğŸ”´ WHY DEDUP IS NEEDED:                                                        â”‚
â”‚  With TP=8, same logical token is dispatched from 8 source ranks.               â”‚
â”‚  If token has 2 local experts here, we receive 8 Ã— 2 = 16 entries!              â”‚
â”‚  Without dedup: AITER processes 16 times â†’ 16Ã— the correct value!              â”‚
â”‚                                                                                 â”‚
â”‚  âœ… THE FIX: Dedup by local_token_idx                                           â”‚
â”‚                                                                                 â”‚
â”‚  # Infer max_tokens_per_rank from position spacing                              â”‚
â”‚  sorted_pos, _ = src_token_pos.sort()                                           â”‚
â”‚  diffs = sorted_pos[1:] - sorted_pos[:-1]                                       â”‚
â”‚  max_diff = diffs.max().item()                                                  â”‚
â”‚  max_tokens_per_rank = max_diff if max_diff > 1000 else 8192                    â”‚
â”‚                                                                                 â”‚
â”‚  # Compute local token index                                                    â”‚
â”‚  local_token_idx = src_token_pos % max_tokens_per_rank                          â”‚
â”‚                                                                                 â”‚
â”‚  # Dedup by local index (merges TP copies)                                      â”‚
â”‚  unique_local_idx, inverse_indices = torch.unique(local_token_idx, ...)         â”‚
â”‚  num_unique = unique_local_idx.shape[0]                                         â”‚
â”‚                                                                                 â”‚
â”‚  EXAMPLE (Decode with TP=8):                                                    â”‚
â”‚    src_token_pos = [100, 8292, 16484, 24676, 32868, 41060, 49252, 57444]        â”‚
â”‚                  = [0Ã—8192+100, 1Ã—8192+100, 2Ã—8192+100, ...]                    â”‚
â”‚    local_token_idx = [100, 100, 100, 100, 100, 100, 100, 100]  â† ALL SAME!     â”‚
â”‚    unique_local_idx = [100]  â†’ num_unique = 1                                   â”‚
â”‚    inverse_indices = [0, 0, 0, 0, 0, 0, 0, 0]                                   â”‚
â”‚                                                                                 â”‚
â”‚  if num_unique < num_valid:                                                     â”‚
â”‚    # Find first occurrence of each unique local token                           â”‚
â”‚    first_indices = scatter_reduce(arange, inverse_indices, reduce='amin')       â”‚
â”‚                                                                                 â”‚
â”‚    # Keep only unique entries                                                   â”‚
â”‚    expert_x = expert_x[first_indices]          â† [1, 7168] after dedup          â”‚
â”‚    recv_weights = recv_weights[first_indices]  â† [1, 8]                         â”‚
â”‚    recv_topk_ids = recv_topk_ids[first_indices]â† [1, 8]                         â”‚
â”‚                                                                                 â”‚
â”‚    # Store for later expansion                                                  â”‚
â”‚    self._dedup_inverse_indices = inverse_indices                                â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STEP 4: AITER EXPERT COMPUTATION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  INPUT TO AITER (after dedup):                                                  â”‚
â”‚    hidden_states = expert_x        â† [N_unique, H]                              â”‚
â”‚    topk_ids = recv_topk_ids        â† [N_unique, 8] GLOBAL expert IDs            â”‚
â”‚    topk_weights = recv_weights     â† [N_unique, 8]                              â”‚
â”‚    expert_map[global_id] â†’ local_id or -1 (filters to local experts)            â”‚
â”‚                                                                                 â”‚
â”‚  AITER COMPUTES (per unique token):                                             â”‚
â”‚    For token with topk_ids = [E0, E1, ..., E7]:                                 â”‚
â”‚      output = Î£ expert_map[Ei] != -1 ? expert_Ei(x) * weight[i] : 0             â”‚
â”‚                                                                                 â”‚
â”‚    Example: topk_ids=[79, 81, 108, 120, 161, 179, 3, 30], rank_offset=160       â”‚
â”‚      local_experts = [161, 179] (experts 160-191 on this rank)                  â”‚
â”‚      output = expert_161(x) * w[4] + expert_179(x) * w[5]                       â”‚
â”‚                                                                                 â”‚
â”‚  OUTPUT:                                                                        â”‚
â”‚    fused_expert_output = [N_unique, H]  â† weighted sum of LOCAL experts         â”‚
â”‚                                                                                 â”‚
â”‚  âœ… CORRECT: Each unique token processed ONCE with all its local experts!      â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STEP 5: WEIGHT & REDUCE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  weight_and_reduce_impl.apply():                                                â”‚
â”‚    - For AITER: weights already applied during expert computation               â”‚
â”‚    - Returns fused_expert_output unchanged (or with minor adjustments)          â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STEP 6: EXPAND FOR COMBINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  If dedup was applied, expand results back to original count:                   â”‚
â”‚                                                                                 â”‚
â”‚  if self._dedup_inverse_indices is not None:                                    â”‚
â”‚    fused_expert_output = fused_expert_output[inverse_indices]                   â”‚
â”‚    # [N_unique, H] â†’ [N_recv, H]                                                â”‚
â”‚    # Example: [1, 7168] â†’ [8, 7168] (8 copies of same result)                   â”‚
â”‚                                                                                 â”‚
â”‚  âœ… All copies have identical results (same token, same computation)            â”‚
â”‚  Combine will route each back to its source rank correctly.                     â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            STEP 7: MORI COMBINE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  combine_result = ep_op.combine(                                                â”‚
â”‚    input=fused_expert_output,     â† [N_recv, H] expert outputs                  â”‚
â”‚    weights=None,                  â† AITER already applied weights               â”‚
â”‚    indices=original_topk_ids,     â† [M_orig, 8] THIS rank's original tokens     â”‚
â”‚  )                                                                              â”‚
â”‚                                                                                 â”‚
â”‚  COMBINE DOES:                                                                  â”‚
â”‚    - Routes expert outputs back to original token owners                        â”‚
â”‚    - Each source rank receives partial results from destination ranks           â”‚
â”‚    - Sums contributions from all expert-owning ranks                            â”‚
â”‚                                                                                 â”‚
â”‚  OUTPUT:                                                                        â”‚
â”‚    combined_x = [max_tokens, H]   â† Fixed-size buffer                           â”‚
â”‚    output = combined_x[:M_orig]   â† Slice to actual token count                 â”‚
â”‚                                                                                 â”‚
â”‚  RESULT: Each original token gets correct weighted sum of all 8 experts!        â”‚
â”‚    output[i] = Î£(j=0..7) expert_topk[j](x[i]) * weight[i,j]                     â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DEDUP EXAMPLES

### Example 1: Decode with TP=8, 1 token per rank

```
BEFORE DEDUP:
  num_valid = 8  (8 entries from 8 source ranks, all same logical token)
  src_token_pos = [100, 8292, 16484, 24676, 32868, 41060, 49252, 57444]
  local_token_idx = src_token_pos % 8192 = [100, 100, 100, 100, 100, 100, 100, 100]
  
AFTER DEDUP:
  num_unique = 1
  expert_x shape: [8, 7168] â†’ [1, 7168]
  
AFTER EXPAND:
  fused_expert_output shape: [1, 7168] â†’ [8, 7168] (8 identical copies)
```

### Example 2: Prefill with TP=8, 8192 tokens per rank

```
BEFORE DEDUP:
  num_valid = 65536  (8 ranks Ã— 8192 tokens, all TP-replicated)
  Each unique token appears 8 times (once per source rank)
  local_token_idx has 8192 unique values, each appearing 8 times
  
AFTER DEDUP:
  num_unique = 8192
  expert_x shape: [65536, 7168] â†’ [8192, 7168]
  
AFTER EXPAND:
  fused_expert_output shape: [8192, 7168] â†’ [65536, 7168]
```

### Example 3: Non-TP mode (EP only)

```
BEFORE DEDUP:
  num_valid = 8192  (8192 unique tokens from various ranks)
  src_token_pos all different AND local_token_idx all different
  
AFTER DEDUP:
  num_unique = 8192  (no dedup, all unique)
  No expansion needed
```

---

## CODE REFERENCE

File: `vllm/model_executor/layers/fused_moe/mori_prepare_finalize.py`

### Key Variables

```python
# Source token position: src_rank Ã— max_tokens + local_idx
src_token_pos = self.ep_op.get_dispatch_src_token_pos()

# Infer max_tokens_per_rank from position spacing
sorted_pos, _ = src_token_pos_valid.sort()
diffs = sorted_pos[1:] - sorted_pos[:-1]
max_diff = diffs.max().item()
max_tokens_per_rank = max_diff if max_diff > 1000 else 8192

# Compute local token index for dedup
local_token_idx = src_token_pos_valid % max_tokens_per_rank

# Dedup by local index
unique_local_idx, inverse_indices = torch.unique(local_token_idx, return_inverse=True)

# First occurrence indices
first_indices = torch.empty(num_unique, dtype=torch.long, device=device)
first_indices.fill_(num_valid)
first_indices.scatter_reduce_(0, inverse_indices, arange, reduce='amin')

# Keep unique entries only
expert_x = expert_x[first_indices]
recv_weights = recv_weights[first_indices]
recv_topk_ids = recv_topk_ids[first_indices]

# Store for expansion later
self._dedup_inverse_indices = inverse_indices
```

### Expansion in finalize

```python
# In _finalize_impl, after AITER computation:
if self._dedup_inverse_indices is not None:
    fused_expert_output = fused_expert_output[self._dedup_inverse_indices]
```

---

## WHY THIS WORKS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CORRECTNESS ARGUMENT                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  1. TP means all ranks have IDENTICAL tokens at each position                   â”‚
â”‚     â†’ Same token dispatched to same experts with same hidden states             â”‚
â”‚                                                                                 â”‚
â”‚  2. Dedup by local_token_idx groups TP copies of same logical token             â”‚
â”‚     â†’ Process once instead of 8Ã— (or NÃ— for TP=N)                               â”‚
â”‚                                                                                 â”‚
â”‚  3. AITER correctly computes weighted sum of LOCAL experts                      â”‚
â”‚     â†’ Each destination rank contributes its partial sum                         â”‚
â”‚                                                                                 â”‚
â”‚  4. Expand creates copies for combine routing                                   â”‚
â”‚     â†’ Same result sent back to all 8 source ranks                               â”‚
â”‚                                                                                 â”‚
â”‚  5. Combine sums partial results from all destination ranks                     â”‚
â”‚     â†’ Each source gets: Î£(all experts) expert(x) * weight                       â”‚
â”‚                                                                                 â”‚
â”‚  RESULT: Correct MoE output with 8Ã— less redundant computation!                 â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DEBUG ENVIRONMENT VARIABLE

Set `VLLM_MORI_DEBUG=1` to enable detailed logging:

```bash
VLLM_MORI_DEBUG=1 python ...
```

Output includes:
- `[MORI SRC_POS DEBUG]` - Source token positions
- `[MORI DEDUP]` - Dedup statistics (total_recv, unique_local_tokens, max_tokens_per_rank)
- `[MORI COMBINE DEBUG]` - Combine input/output shapes and statistics
